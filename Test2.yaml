AWSTemplateFormatVersion: '2010-09-09'
Description: 'AWS CloudFormation template to create an EMR cluster with a single master node'

Resources:

  # ðŸ”¹ S3 Bucket to Store EMR Output
  EMROutputBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: EMRTestFlight2  # Change this to a unique name

  # ðŸ”¹ EMR Cluster with a Single Master Node
  EMRCluster:
    Type: AWS::EMR::Cluster
    Properties:
      Name: MySingleNodeEMRCluster
      ReleaseLabel: emr-7.7.0  # EMR version
      Applications:
        - Name: Hadoop
        - Name: Spark
      Instances:
        Ec2KeyName: ProjectKey  # ðŸ”¹ Replace with your EC2 Key Pair name
        Ec2SubnetId: 'subnet-0606f8f3be7032c5f'  # ðŸ”¹ Replace with your Subnet ID
        MasterInstanceGroup:
          InstanceType: m5.xlarge  # Single master instance
          InstanceCount: 1
      JobFlowRole: EMR_EC2_DefaultRole  # Use an existing IAM role (replace if needed)
      ServiceRole: EMR_DefaultRole  # Replace with your IAM role
      VisibleToAllUsers: true
      # LogUri: s3://my-emr-logs-bucket/  # ðŸ”¹ Optional S3 log location
      VpcId: vpc-0f594472555497448  # ðŸ”¹ Replace with your VPC ID

  # ðŸ”¹ EMR Step to Process Parquet File
  EMRStep:
    Type: AWS::EMR::Step
    Properties:
      Name: ProcessParquetStep
      ActionOnFailure: CONTINUE
      HadoopJarStep:
        Jar: command-runner.jar
        Args:
          - spark-submit
          - s3://projectdatagroup1/CFTScript/CFT_PythonCode_Test1.py  # Updated script
          - --input
          - s3://projectdatagroup1/MergedOutput/part-00000-cd62a82a-9e17-4ae8-bbce-ca6ace9356ad-c000.snappy.parquet  # Parquet file location
          - --output
          - s3://projectdatagroup1/CFTScript/CFT_Output/sample_output.csv  # Single CSV file output
      JobFlowId: !Ref EMRCluster  # ðŸ”¹ Reference to EMR cluster ID

Outputs:
  EMRClusterID:
    Description: "The ID of the created EMR cluster"
    Value: !Ref EMRCluster
